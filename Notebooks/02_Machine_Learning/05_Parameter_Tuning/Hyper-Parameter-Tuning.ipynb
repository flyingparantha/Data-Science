{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will be training various models using different classifiers. Out of them all, we will be choosing the best classifier to give us the most accurate prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "#To check CODE-Run Time of the Block\n",
    "%%time \n",
    "\n",
    "KFold_Score = pd.DataFrame()\n",
    "classifiers = ['Linear SVM', 'Radial SVM', 'LogisticRegression', \n",
    "               'RandomForestClassifier', 'AdaBoostClassifier', \n",
    "               'XGBoostClassifier', 'KNeighborsClassifier','GradientBoostingClassifier']\n",
    "models = [svm.SVC(kernel='linear'),\n",
    "          svm.SVC(kernel='rbf'),\n",
    "          LogisticRegression(max_iter = 1000),\n",
    "          RandomForestClassifier(n_estimators=200, random_state=0),\n",
    "          AdaBoostClassifier(random_state = 0),\n",
    "          xgb.XGBClassifier(n_estimators=100),\n",
    "          KNeighborsClassifier(),\n",
    "          GradientBoostingClassifier(random_state=0)\n",
    "         ]\n",
    "j = 0\n",
    "for i in models:\n",
    "    model = i\n",
    "    cv = KFold(n_splits=5, random_state=0, shuffle=True)\n",
    "    KFold_Score[classifiers[j]] = (cross_val_score(model, #Training_Data, np.ravel(#Training_Labels)\n",
    "                                                   ,scoring = 'accuracy', cv=cv))\n",
    "    j = j+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using K-Folds Cross validation to evaluate the prformance of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = pd.DataFrame(KFold_Score.mean(), index= classifiers)\n",
    "KFold_Score = pd.concat([KFold_Score,mean.T])\n",
    "KFold_Score.index=['Fold 1','Fold 2','Fold 3','Fold 4','Fold 5','Mean']\n",
    "KFold_Score.T.sort_values(by=['Mean'], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most important section of this project. Here, the ultimate goal is to find an optimal combination of hyperparameters that minimizes a predefined loss function to give better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'n_estimators': [ 200,300],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth' : [6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check CODE-Run Time of the Block\n",
    "%%time \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 5)\n",
    "CV_rfc.fit(#Training_Data,#Training_Labels)\n",
    "CV_rfc.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Perform numerous permutations with various hyperparametersand select ones giving the best result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc1=RandomForestClassifier(random_state=0, n_estimators= 200, criterion = 'gini',max_features = 'auto',max_depth = 8)\n",
    "rfc1.fit(#Training_Data,#Training_Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
